{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity DE Nanodegree - Capstone Project - ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is the Jupyter notebook that has the entire ETL code for the Udacity DE Nanodegree - Capstone Project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os.path\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import bitstamp.client\n",
    "from etherscan import Etherscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETH-USD Trading Data\n",
    "In order to gather minute-by-minute ETH-USD Trading Data, it will be necessary to download it from [CryptoDataDownload's website](https://www.cryptodatadownload.com/data/bitstamp/), which will be done in the following section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the ETH-USD Trading Data CSV's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Ethereum Price and Volume data is it doesn't exist\n",
    "\n",
    "eth_bitstamp_urls = [\n",
    "    \"https://www.cryptodatadownload.com/cdd/Bitstamp_ETHUSD_2021_minute.csv\",\n",
    "    \"https://www.cryptodatadownload.com/cdd/Bitstamp_ETHUSD_2020_minute.csv\",\n",
    "    \"https://www.cryptodatadownload.com/cdd/Bitstamp_ETHUSD_2019_minute.csv\"\n",
    "]\n",
    "\n",
    "for url in eth_bitstamp_urls:\n",
    "    \n",
    "    file_name = url.split(\"Bitstamp_\")[-1]\n",
    "    if not os.path.isfile(\"/eth-usd/\" + file_name):\n",
    "        urllib.request.urlretrieve(url, \"eth-usd/\" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's open the recently downloaded CSV files and describe them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****ETHUSD_2019_minute.csv****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elede\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (0,3,4,5,6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         https://www.CryptoDataDownload.com\n",
      "count                              525600.0\n",
      "unique                             299560.0\n",
      "top                                     0.0\n",
      "freq                               182088.0\n",
      "missing                                 0.0\n",
      "****ETHUSD_2020_minute.csv****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elede\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (0,3,4,5,6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         https://www.CryptoDataDownload.com\n",
      "count                              487723.0\n",
      "unique                             332567.0\n",
      "top                                     0.0\n",
      "freq                               141599.0\n",
      "missing                                 0.0\n",
      "****ETHUSD_2021_minute.csv****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elede\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (0,3,4,5,6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         https://www.CryptoDataDownload.com\n",
      "count                              482834.0\n",
      "unique                             447912.0\n",
      "top                                     0.0\n",
      "freq                                29269.0\n",
      "missing                                 0.0\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"eth-usd\"):\n",
    "    print(\"****\" +file+ \"****\")\n",
    "    eth_data = pd.read_csv(\"eth-usd/\" + file)\n",
    "    desc_data = eth_data.describe(include='all')\n",
    "    desc_null = eth_data.isnull().sum().to_frame(name = 'missing').T\n",
    "    print(pd.concat([desc_data, desc_null]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there's something wrong with these files. By taking a look at one of these files, it can be noticed that the first line of the file does not correspond to the headers or to relevant data:\n",
    "\n",
    "![title](./img/img_1.png)\n",
    "\n",
    "Thus, it'll be removed using the ```skiprows``` argument from ```pd.read_csv``` method. Let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****ETHUSD_2019_minute.csv****\n",
      "                 unix                 date   symbol           open  \\\n",
      "count    5.255990e+05               525599   525599  525599.000000   \n",
      "unique            NaN               525599        1            NaN   \n",
      "top               NaN  2019-12-31 23:59:00  ETH/USD            NaN   \n",
      "freq              NaN                    1   525599            NaN   \n",
      "mean     1.562069e+09                  NaN      NaN     180.735784   \n",
      "std      9.103650e+06                  NaN      NaN      50.623448   \n",
      "min      1.546301e+09                  NaN      NaN     100.530000   \n",
      "25%      1.554185e+09                  NaN      NaN     141.160000   \n",
      "50%      1.562069e+09                  NaN      NaN     173.500000   \n",
      "75%      1.569953e+09                  NaN      NaN     209.020000   \n",
      "max      1.577837e+09                  NaN      NaN     363.170000   \n",
      "missing  0.000000e+00                    0        0       0.000000   \n",
      "\n",
      "                  high            low          close     Volume ETH  \\\n",
      "count    525599.000000  525599.000000  525599.000000  525599.000000   \n",
      "unique             NaN            NaN            NaN            NaN   \n",
      "top                NaN            NaN            NaN            NaN   \n",
      "freq               NaN            NaN            NaN            NaN   \n",
      "mean        180.792075     180.679193     180.738772      30.140162   \n",
      "std          50.661485      50.582316      50.622946     107.896683   \n",
      "min         100.590000     100.000000     100.430000       0.000000   \n",
      "25%         141.180000     141.140000     141.160000       0.000000   \n",
      "50%         173.520000     173.460000     173.500000       0.750000   \n",
      "75%         209.080000     208.980000     209.030000      16.720298   \n",
      "max         363.180000     362.000000     362.910000   12067.972220   \n",
      "missing       0.000000       0.000000       0.000000       0.000000   \n",
      "\n",
      "           Volume USD  \n",
      "count    5.255990e+05  \n",
      "unique            NaN  \n",
      "top               NaN  \n",
      "freq              NaN  \n",
      "mean     5.711573e+03  \n",
      "std      2.079824e+04  \n",
      "min      0.000000e+00  \n",
      "25%      0.000000e+00  \n",
      "50%      1.291165e+02  \n",
      "75%      3.062396e+03  \n",
      "max      1.945840e+06  \n",
      "missing  0.000000e+00  \n",
      "   \n",
      "****ETHUSD_2020_minute.csv****\n",
      "                 unix                 date   symbol           open  \\\n",
      "count    4.877220e+05               487722   487722  487722.000000   \n",
      "unique            NaN               487722        1            NaN   \n",
      "top               NaN  2020-12-31 23:59:00  ETH/USD            NaN   \n",
      "freq              NaN                    1   487722            NaN   \n",
      "mean     1.592550e+09                  NaN      NaN     283.690148   \n",
      "std      8.593247e+06                  NaN      NaN     123.364995   \n",
      "min      1.577837e+09                  NaN      NaN      88.310000   \n",
      "25%      1.585153e+09                  NaN      NaN     194.110000   \n",
      "50%      1.592468e+09                  NaN      NaN     238.970000   \n",
      "75%      1.599784e+09                  NaN      NaN     378.130000   \n",
      "max      1.609459e+09                  NaN      NaN     757.290000   \n",
      "missing  0.000000e+00                    0        0       0.000000   \n",
      "\n",
      "                  high            low          close     Volume ETH  \\\n",
      "count    487722.000000  487722.000000  487722.000000  487722.000000   \n",
      "unique             NaN            NaN            NaN            NaN   \n",
      "top                NaN            NaN            NaN            NaN   \n",
      "freq               NaN            NaN            NaN            NaN   \n",
      "mean        283.782294     283.595907     283.691397      36.046034   \n",
      "std         123.423350     123.304520     123.366044     131.442315   \n",
      "min          89.530000      88.200000      89.010000       0.000000   \n",
      "25%         194.170000     194.050000     194.120000       0.000000   \n",
      "50%         239.000000     238.935000     238.970000       4.257530   \n",
      "75%         378.240000     378.010000     378.140000      28.354464   \n",
      "max         758.500000     755.480000     756.520000   11594.049996   \n",
      "missing       0.000000       0.000000       0.000000       0.000000   \n",
      "\n",
      "           Volume USD  \n",
      "count    4.877220e+05  \n",
      "unique            NaN  \n",
      "top               NaN  \n",
      "freq              NaN  \n",
      "mean     1.057739e+04  \n",
      "std      4.092001e+04  \n",
      "min      0.000000e+00  \n",
      "25%      0.000000e+00  \n",
      "50%      1.076215e+03  \n",
      "75%      8.162231e+03  \n",
      "max      5.322025e+06  \n",
      "missing  0.000000e+00  \n",
      "   \n",
      "****ETHUSD_2021_minute.csv****\n",
      "                 unix                 date   symbol           open  \\\n",
      "count    4.828330e+05               482833   482833  482833.000000   \n",
      "unique            NaN               482833        1            NaN   \n",
      "top               NaN  2021-12-02 07:13:00  ETH/USD            NaN   \n",
      "freq              NaN                    1   482833            NaN   \n",
      "mean     1.623944e+09                  NaN      NaN    2659.999426   \n",
      "std      8.362922e+06                  NaN      NaN     995.866053   \n",
      "min      1.609459e+09                  NaN      NaN     717.010000   \n",
      "25%      1.616702e+09                  NaN      NaN    1835.080000   \n",
      "50%      1.623944e+09                  NaN      NaN    2464.990000   \n",
      "75%      1.631187e+09                  NaN      NaN    3413.560000   \n",
      "max      1.638429e+09                  NaN      NaN    4866.450000   \n",
      "missing  0.000000e+00                    0        0       0.000000   \n",
      "\n",
      "                  high            low          close     Volume ETH  \\\n",
      "count    482833.000000  482833.000000  482833.000000  482833.000000   \n",
      "unique             NaN            NaN            NaN            NaN   \n",
      "top                NaN            NaN            NaN            NaN   \n",
      "freq               NaN            NaN            NaN            NaN   \n",
      "mean       2661.482401    2658.449080    2659.959741      38.932549   \n",
      "std         996.089253     995.643721     995.872449     123.826754   \n",
      "min         718.040000     716.240000     717.020000       0.000000   \n",
      "25%        1835.910000    1834.300000    1835.130000       1.887000   \n",
      "50%        2466.900000    2463.120000    2464.800000       9.980000   \n",
      "75%        3415.170000    3411.780000    3413.460000      32.335335   \n",
      "max        4868.790000    4864.100000    4867.960000   12491.743940   \n",
      "missing       0.000000       0.000000       0.000000       0.000000   \n",
      "\n",
      "           Volume USD  \n",
      "count    4.828330e+05  \n",
      "unique            NaN  \n",
      "top               NaN  \n",
      "freq              NaN  \n",
      "mean     8.552353e+04  \n",
      "std      2.591240e+05  \n",
      "min      0.000000e+00  \n",
      "25%      5.098995e+03  \n",
      "50%      2.383542e+04  \n",
      "75%      7.421535e+04  \n",
      "max      1.611494e+07  \n",
      "missing  0.000000e+00  \n",
      "   \n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"eth-usd\"):\n",
    "    print(\"****\" +file+ \"****\")\n",
    "    eth_data = pd.read_csv(\"eth-usd/\" + file, skiprows=1)\n",
    "    desc_data = eth_data.describe(include='all')\n",
    "    desc_null = eth_data.isnull().sum().to_frame(name = 'missing').T\n",
    "    print(pd.concat([desc_data, desc_null]))\n",
    "    print(\"   \")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good news here: There are no missing values in the entirety of the files. Now, let's analyze above's output, variable by variable:\n",
    "\n",
    "- **unix**: this is the UNIX timestamp of the time the data row was generated. Its max and min values are in line with plausible values for a UNIX timestamp;\n",
    "- **date**: this is the datetime timestamp of the time the data row was generated. The number of unique values is equal to the number of rows, so all of the values in this column are unique. Nevertheless, we need to run further testing on this column regarding the formatting of the date;\n",
    "- **symbol**: the currency pair of the data. In this case, it should always be ```ETH/USD```, which is the case for all of the files, as per above's output;\n",
    "- **open**,  **high**, **low** and **close**: these are the opening, closing, highest and lowest prices (USD per ETH) for the minute timeframe starting at **unix**. The maximum and minimum prices sem to be in line with general domain knowledge of ```ETH/USD``` market;\n",
    "- **Volume ETH** and **Volume USD**: the number of ETH and USD that were transacted on the minute timeframe starting at **unix**.\n",
    "\n",
    "Now, let's go to the data testing section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data quality tests will be performed after changing column names to ones that are more descriptive:\n",
    "\n",
    "- *Data types must match the following, respectively*: int64, object, object, float64, float64, float64, float64, float64, float64;\n",
    "- *Unique value for the currency_pair column should be 'ETH/USD'*;\n",
    "- *Unix timestamps can't be greater than now's timestamp*;\n",
    "- *Datetime cannot be more recent than now*;\n",
    "- *Unix timestamp must correspond to its respective datetime timestamp (in line with previous concerns regarding the **date** field)*;\n",
    "- *The timelapse between two consecutive data rows should be 60 seconds*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The timelapse between two consecutive data rows should be 60 seconds.\n"
     ]
    }
   ],
   "source": [
    "try:  \n",
    "  dfs = [pd.read_csv(\"eth-usd/\" + file, skiprows=1)\n",
    "          for file in os.listdir(\"eth-usd\")]\n",
    "  eth_data = pd.concat(dfs, \n",
    "                          axis=0).rename(\n",
    "                                          columns={\n",
    "                                                  \"unix\":\"unix_timestamp\",\n",
    "                                                  \"date\":\"date_time\",\n",
    "                                                  \"symbol\":\"currency_pair\",\n",
    "                                                  \"open\":\"open_price\",\n",
    "                                                  \"high\":\"high_price\",\n",
    "                                                  \"low\":\"low_price\",\n",
    "                                                  \"close\":\"close_price\",\n",
    "                                                  'Volume ETH':'volume_1',\n",
    "                                                  'Volume USD':'volume_2'})\n",
    "  \n",
    "  # Order data for further timelapse data test\n",
    "  eth_data = eth_data.reset_index(drop=True)\n",
    "  eth_data.sort_values(by='unix_timestamp', ascending=True, inplace=True)\n",
    "  eth_data = eth_data.reset_index(drop=True)\n",
    "\n",
    "  # Data types must match expected ones, as per data_types list:\n",
    "  columns = list(eth_data.columns)  \n",
    "  data_types = [np.int64, object, object, np.float64, np.float64,\n",
    "                  np.float64, np.float64, np.float64, np.float64]\n",
    "  assert all([eth_data[columns[i]].dtype == data_types[i]\n",
    "          for i in range(len(columns))]), \\\n",
    "          \"Data types must match expected ones, as per data_types list.\"\n",
    "\n",
    "  # Unique value for the currency_pair column should be 'ETH/USD':\n",
    "  assert eth_data['currency_pair'].unique() == ['ETH/USD'], \\\n",
    "          \"Unique value for the currency_pair column should be 'ETH/USD'.\"\n",
    "\n",
    "  # Unix timestamps can't be greater than now's timestamp:\n",
    "  assert int(time.time()) >= eth_data['unix_timestamp'].max(), \\\n",
    "          \"Unix timestamps can't be greater than now's timestamp.\"\n",
    "\n",
    "  # Datetime cannot be more recent than now\n",
    "  assert pd.to_datetime(eth_data['date_time']).max() <= \\\n",
    "  pd.to_datetime(int(time.time()), unit = 's'), \\\n",
    "          \"Datetime cannot be more recent than now.\"\n",
    "\n",
    "  # Unix timestamp must correspond to datetime timestamp\n",
    "  eth_data['unix_date'] = pd.to_datetime(\n",
    "                                          eth_data['unix_timestamp'], \n",
    "                                          unit = 's'\n",
    "                                        ) \n",
    "  assert all(eth_data['unix_date'] == eth_data['date_time']), \\\n",
    "        \"Unix timestamp must correspond to datetime timestamp.\"\n",
    "\n",
    "  # The timelapse between two consecutive data rows should be 60 seconds\n",
    "  # NOTE: the column 'diff' will have a value of nan in the first row because\n",
    "  # there are no rows before the first one.\n",
    "  eth_data['diff'] = eth_data['unix_timestamp'].diff()\n",
    "  assert max(eth_data['diff'][1:eth_data.shape[0]-1]) == 60, \\\n",
    "        \"The timelapse between two consecutive data rows should be 60 seconds.\"\n",
    "  print(\"All tests passed!\")\n",
    "\n",
    "except Exception as e: \n",
    "    print(\"Error: \" + str(e))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but the timelapse data test have been passed. Let's delve into the infringing rows to see what happens (let's not forget that the first row of the ```diff``` column in the above code snippet has a value of ```nan```, so it will be removed from this analysis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with diff = 120\n",
      "         unix_timestamp            date_time currency_pair  open_price  \\\n",
      "525599       1577836860  2020-01-01 00:01:00       ETH/USD      128.63   \n",
      "1013321      1609459260  2021-01-01 00:01:00       ETH/USD      738.63   \n",
      "\n",
      "         high_price  low_price  close_price   volume_1      volume_2  \\\n",
      "525599       128.63     128.63       128.63   0.000000      0.000000   \n",
      "1013321      740.50     738.63       740.50  15.054058  11147.529979   \n",
      "\n",
      "                  unix_date   diff  \n",
      "525599  2020-01-01 00:01:00  120.0  \n",
      "1013321 2021-01-01 00:01:00  120.0  \n",
      "--------------------------------------------------\n",
      "\n",
      "Rows with diff = 2359080\n",
      "        unix_timestamp            date_time currency_pair  open_price  \\\n",
      "996515      1608450840  2020-12-20 07:54:00       ETH/USD      656.15   \n",
      "\n",
      "        high_price  low_price  close_price   volume_1      volume_2  \\\n",
      "996515      656.36     656.15       656.36  18.000252  11814.645298   \n",
      "\n",
      "                 unix_date       diff  \n",
      "996515 2020-12-20 07:54:00  2359080.0  \n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_diff = list(eth_data['diff'][1:eth_data.shape[0]-1].unique())\n",
    "unique_diff = [i for i in unique_diff if i != 60]\n",
    "\n",
    "for i in unique_diff:    \n",
    "    print(\"Rows with diff = \" + str(int(i)))\n",
    "    print(eth_data[eth_data['diff'] == i])\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 values other than 60 seconds: 120 and 2359080. Let's explore the vicinities of the infringing rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vicinities for instances of diff =  120.0\n",
      "        unix_timestamp            date_time   diff\n",
      "525596      1577836620  2019-12-31 23:57:00   60.0\n",
      "525597      1577836680  2019-12-31 23:58:00   60.0\n",
      "525598      1577836740  2019-12-31 23:59:00   60.0\n",
      "525599      1577836860  2020-01-01 00:01:00  120.0\n",
      "525600      1577836920  2020-01-01 00:02:00   60.0\n",
      "525601      1577836980  2020-01-01 00:03:00   60.0\n",
      "525602      1577837040  2020-01-01 00:04:00   60.0\n",
      "         unix_timestamp            date_time   diff\n",
      "1013318      1609459020  2020-12-31 23:57:00   60.0\n",
      "1013319      1609459080  2020-12-31 23:58:00   60.0\n",
      "1013320      1609459140  2020-12-31 23:59:00   60.0\n",
      "1013321      1609459260  2021-01-01 00:01:00  120.0\n",
      "1013322      1609459320  2021-01-01 00:02:00   60.0\n",
      "1013323      1609459380  2021-01-01 00:03:00   60.0\n",
      "1013324      1609459440  2021-01-01 00:04:00   60.0\n",
      "\n",
      "Vicinities for instances of diff =  2359080.0\n",
      "        unix_timestamp            date_time       diff\n",
      "996512      1606091640  2020-11-23 00:34:00       60.0\n",
      "996513      1606091700  2020-11-23 00:35:00       60.0\n",
      "996514      1606091760  2020-11-23 00:36:00       60.0\n",
      "996515      1608450840  2020-12-20 07:54:00  2359080.0\n",
      "996516      1608450900  2020-12-20 07:55:00       60.0\n",
      "996517      1608450960  2020-12-20 07:56:00       60.0\n",
      "996518      1608451020  2020-12-20 07:57:00       60.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in unique_diff:  \n",
    "    indexes = eth_data[eth_data['diff'] == i].index\n",
    "    print(\"Vicinities for instances of diff = \", str(i))\n",
    "    for j in indexes:\n",
    "        print(eth_data.loc[j-3:j+3, ['unix_timestamp', 'date_time', 'diff']]) \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking a look at above input, there are a couple of conclusions that can be derived:\n",
    "- The 120 ```diff``` instances correspond to the transition between different years. It seems there's no data for ```2020-01-01 00:00:00``` and ```2021-01-01 00:00:00```. It is possible that the exchange's API stops working due to some unintended bug or some scheduled maintenance at the end of the year;\n",
    "- The 2359080 ```diff``` instance definitely corresponds to a big gap in the data that should be accounted for and addressed at a further stage as future work.\n",
    "\n",
    "Data will be persisted in the next section.\n",
    "Now, let's persist these data in a containerized, local Postgres DB. NOTE: this can be done on any postgres-based DB; simply change the endpoint data accordingly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data persistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's persist these data in a containerized, local Postgres DB. NOTE: this can be done on any postgres-based DB; simply change the endpoint data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data schema and trading table\n",
    "engine = create_engine(\n",
    "          'postgresql+psycopg2://postgres:postgres@localhost:5432/postgres'\n",
    "          )\n",
    "schema_creation = \"\"\"\n",
    "                  DROP SCHEMA IF EXISTS crypto CASCADE;\n",
    "                  CREATE SCHEMA IF NOT EXISTS crypto;\n",
    "                  --DROP TABLE IF EXISTS crypto.staging_trading\n",
    "                  CREATE TABLE IF NOT EXISTS crypto.staging_trading (    \n",
    "                  unix_timestamp BIGINT\n",
    "                  , date_time TIMESTAMP\n",
    "                  , currency_pair VARCHAR(20)\n",
    "                  , open_price NUMERIC\n",
    "                  , high_price NUMERIC\n",
    "                  , low_price NUMERIC\n",
    "                  , close_price NUMERIC\n",
    "                  , volume_1 NUMERIC\n",
    "                  , volume_2 NUMERIC\n",
    "                  );\n",
    "                  \"\"\"\n",
    "with engine.connect() as con:\n",
    "    con.execute(schema_creation)\n",
    "    eth_data = eth_data[[\"unix_timestamp\", \"date_time\", \"currency_pair\",\n",
    "    \"open_price\", \"high_price\", \"low_price\", \"close_price\",\n",
    "    'volume_1', 'volume_2']]\n",
    "    eth_data.to_sql('staging_trading',                   \n",
    "                    con, \n",
    "                    schema = 'crypto',\n",
    "                    if_exists = 'append',\n",
    "                    index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the ether trading data source has benn taken care of, let's proceed with the etherscan datasource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etherscan Network Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Download\n",
    "\n",
    "This datasource comes from an API ([Documentation](https://docs.etherscan.io/)). In order to gather data from it, a request should be made to the corresponding endpoint by using a start date, an end date and an API key previously gathered from Etherscan's website. For this, a function will be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"D61F9X3T2ECDGI6YHPV45UFGR6TE9M72V8\"\n",
    "url_template = 'https://api.etherscan.io/api?module=stats&action=chainsize&startdate={}&enddate={}&clienttype=geth&syncmode=default&sort=asc&apikey={}'\n",
    "\n",
    "def getEtherScanResults(start_date:str, end_date:str, \n",
    "                        api_key:str, url_template:str):\n",
    "\n",
    "  response = requests.get(url_template.format(start_date, end_date, api_key))\n",
    "  if response.status_code == 200:\n",
    "      return pd.json_normalize(response.json()['result'])\n",
    "  else:\n",
    "      return \"invalid response\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this function and its outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   blockNumber chainTimeStamp     chainSize clientType syncMode\n",
      "0      7156164     2019-02-01  184726421279       Geth  Default\n",
      "1      7161012     2019-02-02  184726654448       Geth  Default\n",
      "2      7165949     2019-02-03  184726769049       Geth  Default\n",
      "3      7170805     2019-02-04  186974874323       Geth  Default\n",
      "4      7175752     2019-02-05  186974913559       Geth  Default\n",
      "5      7180654     2019-02-06  186974923662       Geth  Default\n",
      "6      7185533     2019-02-07  186974939161       Geth  Default\n",
      "7      7190465     2019-02-08  186974941698       Geth  Default\n",
      "8      7195382     2019-02-09  188036647969       Geth  Default\n",
      "9      7200281     2019-02-10  188036745122       Geth  Default\n",
      "10     7204582     2019-02-11  189825908951       Geth  Default\n",
      "11     7208771     2019-02-12  189825138765       Geth  Default\n",
      "12     7213043     2019-02-13  191029008588       Geth  Default\n",
      "13     7217203     2019-02-14  191029044688       Geth  Default\n",
      "14     7221377     2019-02-15  191029043090       Geth  Default\n",
      "15     7225536     2019-02-16  191029045208       Geth  Default\n",
      "16     7229750     2019-02-17  193165253566       Geth  Default\n",
      "17     7233897     2019-02-18  193137877427       Geth  Default\n",
      "18     7238097     2019-02-19  193137884219       Geth  Default\n",
      "19     7242392     2019-02-20  193137888523       Geth  Default\n",
      "20     7246851     2019-02-21  193137897277       Geth  Default\n",
      "21     7250875     2019-02-22  194181810792       Geth  Default\n",
      "22     7255115     2019-02-23  194182026829       Geth  Default\n",
      "23     7259664     2019-02-24  196325633666       Geth  Default\n",
      "24     7263727     2019-02-25  196296727498       Geth  Default\n",
      "25     7267963     2019-02-26  197073035945       Geth  Default\n",
      "26     7272243     2019-02-27  197073058856       Geth  Default\n"
     ]
    }
   ],
   "source": [
    "start_date = '2019-02-01'\n",
    "end_date = '2019-02-27'\n",
    "\n",
    "print(getEtherScanResults(start_date, end_date, API_KEY, url_template))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the function has been tested, let's gather all the data from 2019-01-01 onwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_number</th>\n",
       "      <th>chain_time_stamp</th>\n",
       "      <th>chain_size</th>\n",
       "      <th>client_type</th>\n",
       "      <th>sync_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7111289</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>180427595683</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7116274</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>180427599016</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7121375</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>181437999437</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7126462</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>181438824915</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7131517</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>181439384907</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>13699166</td>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>1167828425568</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>13705423</td>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>1170199295600</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>13711627</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>1172134023323</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>13717878</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>1174116456497</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>13724121</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>1176081509097</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1046 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     block_number chain_time_stamp     chain_size client_type sync_mode\n",
       "0         7111289       2019-01-23   180427595683        Geth   Default\n",
       "1         7116274       2019-01-24   180427599016        Geth   Default\n",
       "2         7121375       2019-01-25   181437999437        Geth   Default\n",
       "3         7126462       2019-01-26   181438824915        Geth   Default\n",
       "4         7131517       2019-01-27   181439384907        Geth   Default\n",
       "...           ...              ...            ...         ...       ...\n",
       "1041     13699166       2021-11-28  1167828425568        Geth   Default\n",
       "1042     13705423       2021-11-29  1170199295600        Geth   Default\n",
       "1043     13711627       2021-11-30  1172134023323        Geth   Default\n",
       "1044     13717878       2021-12-01  1174116456497        Geth   Default\n",
       "1045     13724121       2021-12-02  1176081509097        Geth   Default\n",
       "\n",
       "[1046 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etherscan_data = pd.DataFrame(columns = [\n",
    "                                          'blockNumber',\n",
    "                                          'chainTimeStamp', \n",
    "                                          'chainSize', \n",
    "                                          'clientType', \n",
    "                                          'syncMode'\n",
    "                                          ]\n",
    "                              )\n",
    "\n",
    "max_abs_date = max(eth_data['date_time']).split(' ')[0]\n",
    "min_abs_date = min(eth_data['date_time']).split(' ')[0]\n",
    "datelist = pd.date_range(start=min_abs_date,end=max_abs_date).tolist()\n",
    "\n",
    "for i in range((len(datelist)//30) + 1):\n",
    "  \n",
    "    date_range = [i.strftime('%Y-%m-%d') for i in datelist[(i*30):(((i+1)*30))]]\n",
    "    start_date = date_range[0]\n",
    "    end_date = date_range[-1]\n",
    "    response_df = getEtherScanResults(start_date, end_date, \n",
    "                                        API_KEY, url_template)\n",
    "    if response_df is str and response_df == \"invalid response\":\n",
    "        continue\n",
    "    etherscan_data = etherscan_data.append(response_df, ignore_index=True)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "\n",
    "etherscan_data = etherscan_data.\\\n",
    "                  rename(columns={\n",
    "                                  \"blockNumber\":\"block_number\",\n",
    "                                  \"chainTimeStamp\":\"chain_time_stamp\",\n",
    "                                  \"chainSize\":\"chain_size\",\n",
    "                                  \"clientType\":\"client_type\",\n",
    "                                  \"syncMode\":\"sync_mode\"}\n",
    "                        )\n",
    "etherscan_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go, then, to the Data Exploration section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "\n",
    "Let's see how does the data look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        block_number chain_time_stamp    chain_size client_type sync_mode\n",
      "count           1046             1046          1046        1046      1046\n",
      "unique          1046             1045          1039           1         1\n",
      "top          7111289       2020-08-01  229824047924        Geth   Default\n",
      "freq               1                2             4        1046      1046\n",
      "missing            0                0             0           0         0\n"
     ]
    }
   ],
   "source": [
    "### Data exploration\n",
    "\n",
    "desc_data = etherscan_data.describe(include='all')\n",
    "desc_null = etherscan_data.isnull().sum().to_frame(name = 'missing').T\n",
    "print(pd.concat([desc_data, desc_null]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, good news: no missing values in this dataframe. Now, let's analyze above's output, variable by variable:\n",
    "\n",
    "- **block_number**: the number of blocks generated in the Ethereum network, as of **chain_time_stamp** date (hence the \"Blockchain\" moniker). This column seems to be in line with the general domain knowledge about what that number should be;\n",
    "- **chain_time_stamp**: the date corresponding to the moment the data row was gathered. It seems there's duplicate data for one of the days, as the count of rows is greater than the count of unique values by 1;\n",
    "- **chain_size**: the size (in bytes) of the Ethereum blockchain. All of the values should be unique here (it's nearly impossible that the Ethereum blockchain remains the same size from a given day to the next, as there're always some transactions being performed);\n",
    "- **client_type**: the Ethereum blockchain client that was used to extract the data row from the Ethereum blockchain (a list of the clients can be found [here](https://media.consensys.net/an-definitive-list-of-ethereum-developer-tools-2159ce865974)). Geth was chosen due to familiarity with it, but any client can be chose. All of the rows have the same ```Geth``` value, so no concerns here;\n",
    "- **sync_mode**: the way the Ethereum network's state is recreated (```FAST```, by default, i.e. the Ethereum blockchain is not generated incrementally, block by block). Similar to **client_type**, all of the rows have the same ```default``` value, so no concerns here.\n",
    "\n",
    "Now, let's go to the data testing section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quality testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the concerns found in the data exploration section will be addressed: \n",
    "\n",
    "- Duplicate **chain_time_stamp** values;\n",
    "- Duplicate **chain_size** values.\n",
    "\n",
    "Let's begin with the first concern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_number</th>\n",
       "      <th>chain_time_stamp</th>\n",
       "      <th>chain_size</th>\n",
       "      <th>client_type</th>\n",
       "      <th>sync_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>10570514</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>473642779532</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>10570758</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>473651278977</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    block_number chain_time_stamp    chain_size client_type sync_mode\n",
       "556     10570514       2020-08-01  473642779532        Geth   Default\n",
       "557     10570758       2020-08-01  473651278977        Geth   Default"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etherscan_dt_count = pd.value_counts(etherscan_data.chain_time_stamp).to_frame().reset_index()\n",
    "repeat_date = etherscan_dt_count[etherscan_dt_count['chain_time_stamp'] == 2]['index']\n",
    "etherscan_data[etherscan_data['chain_time_stamp'] == repeat_date[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some sort of double counting in that day. There are a couple of ways to deal with this:\n",
    "\n",
    "- Ask the source of these data for clarifications: the best way, but it's uncertain whether if the source is reachable or not;\n",
    "- Interpolate **block_number** and **chain_size** values: it may be a good way of combining the two rows, but the resulting row is not the truth;\n",
    "- Eliminate one of the rows: easy, retains one of the two versions of the truth, but completely ignores the other.\n",
    "\n",
    "For the sake of this project, let's go with the third alternative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "etherscan_data = etherscan_data[etherscan_data['block_number'] != 10570514].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the rows has been erased successfully. Now, let's delve into the second concern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_number</th>\n",
       "      <th>chain_time_stamp</th>\n",
       "      <th>chain_size</th>\n",
       "      <th>client_type</th>\n",
       "      <th>sync_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7111289</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>180427595683</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7116274</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>180427599016</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7121375</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>181437999437</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7126462</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>181438824915</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7131517</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>181439384907</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>13699166</td>\n",
       "      <td>2021-11-28</td>\n",
       "      <td>1167828425568</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>13705423</td>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>1170199295600</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>13711627</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>1172134023323</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>13717878</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>1174116456497</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>13724121</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>1176081509097</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1034 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     block_number chain_time_stamp     chain_size client_type sync_mode\n",
       "0         7111289       2019-01-23   180427595683        Geth   Default\n",
       "1         7116274       2019-01-24   180427599016        Geth   Default\n",
       "2         7121375       2019-01-25   181437999437        Geth   Default\n",
       "3         7126462       2019-01-26   181438824915        Geth   Default\n",
       "4         7131517       2019-01-27   181439384907        Geth   Default\n",
       "...           ...              ...            ...         ...       ...\n",
       "1041     13699166       2021-11-28  1167828425568        Geth   Default\n",
       "1042     13705423       2021-11-29  1170199295600        Geth   Default\n",
       "1043     13711627       2021-11-30  1172134023323        Geth   Default\n",
       "1044     13717878       2021-12-01  1174116456497        Geth   Default\n",
       "1045     13724121       2021-12-02  1176081509097        Geth   Default\n",
       "\n",
       "[1034 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etherscan_chain_count = pd.value_counts(etherscan_data.chain_size).to_frame().reset_index().head(10)\n",
    "repeat_chain = etherscan_chain_count[etherscan_chain_count['chain_size'] > 1]['index']\n",
    "etherscan_data[~etherscan_data['chain_size'].isin(repeat_chain)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the duplicate chain_size cases have to do with consecutive days, which suggests there may be some technical bug related to the client, or maybe some human error that is not immediately verifiable. Thus, for the sake of this project, it will be left that way, but on a real-life scenario, it is advised to further delve into these inconsistencies (including the ones discussed in the first concern).\n",
    "\n",
    "Regarding the formal data quality tests to be performed in this data source, these will be performed:\n",
    "\n",
    "- *Data types must match the following, respectively*: int64, object, object, float64, float64, float64, float64, float64, float64;\n",
    "- *Unique value for the client_type and sync_mode columns should be 'Geth' and 'Default', respectively*;\n",
    "- *chain_time_stamp cannot be more recent than now*;\n",
    "- *The timelapse between two date-ordered, consecutive data rows should be 1 day*;\n",
    "- *Given the order in the previous item, both block_number and chain_size should grow (or at least remain the same) as time passes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: chain_size should grow (or at least remain the same) as time passes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Order data for further timelapse data test\n",
    "etherscan_data = etherscan_data.reset_index(drop=True)\n",
    "etherscan_data.sort_values(by='chain_time_stamp', ascending=True, inplace=True)\n",
    "etherscan_data = etherscan_data.reset_index(drop=True)\n",
    "\n",
    "#Type conversions for better workability\n",
    "etherscan_data = etherscan_data.astype({\n",
    "                                        'block_number': 'int64',\n",
    "                                        'chain_size': 'int64' \n",
    "                                        })\n",
    "try:\n",
    "    # Data types must match expected ones, as per data_types list:\n",
    "    columns = list(etherscan_data.columns)    \n",
    "    data_types = [np.int64, object, np.int64, object, object]\n",
    "    assert all([etherscan_data[columns[i]].dtype == data_types[i]\n",
    "            for i in range(len(columns))]), \\\n",
    "            \"Data types must match expected ones, as per data_types list.\"\n",
    "\n",
    "    # Unique value for the client_type and sync_mode columns \n",
    "    # should be 'Geth' and 'Default', respectively:\n",
    "    assert etherscan_data['client_type'].unique() == ['Geth'] and \\\n",
    "        etherscan_data['sync_mode'].unique() == ['Default'], \\\n",
    "        \"\"\"Unique value for the client_type and sync_mode columns \n",
    "        should be 'Geth' and 'Default', respectively\"\"\"\n",
    "\n",
    "    # chain_time_stamp cannot be more recent than now\n",
    "    assert pd.to_datetime(etherscan_data['chain_time_stamp']).max() <=\\\n",
    "            pd.to_datetime(int(time.time()), unit = 's'), \\\n",
    "            \"chain_time_stamp cannot be more recent than now\"\n",
    "\n",
    "    # block_number should grow (or at least remain the same) as time passes \n",
    "    etherscan_data['block_diff'] = etherscan_data['block_number'].diff()\n",
    "    assert all(etherscan_data['block_diff']\\\n",
    "        [1:etherscan_data.shape[0]-1] >= 0), \\\n",
    "    \"block_number should grow (or at least remain the same) as time passes.\"\n",
    "\n",
    "    # chain_size should grow (or at least remain the same) as time passes \n",
    "    etherscan_data['chain_diff'] = etherscan_data['chain_size'].diff()\n",
    "    assert all(etherscan_data['chain_diff']\\\n",
    "        [1:etherscan_data.shape[0]-1] >= 0), \\\n",
    "    \"chain_size should grow (or at least remain the same) as time passes.\"\n",
    "\n",
    "except Exception as e: \n",
    "    print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but the monotonically increasing chain size check have passed. It can be seen that there are some occasions in which the chain size decreases from one day to another. Let's explore these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_number</th>\n",
       "      <th>chain_time_stamp</th>\n",
       "      <th>chain_size</th>\n",
       "      <th>client_type</th>\n",
       "      <th>sync_mode</th>\n",
       "      <th>block_diff</th>\n",
       "      <th>chain_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7208771</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>189825138765</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>4189.0</td>\n",
       "      <td>-7.701860e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7221377</td>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>191029043090</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>4174.0</td>\n",
       "      <td>-1.598000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7233897</td>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>193137877427</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>-2.737614e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7263727</td>\n",
       "      <td>2019-02-25</td>\n",
       "      <td>196296727498</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>-2.890617e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7318905</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>201604491690</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>6414.0</td>\n",
       "      <td>-2.674129e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>13214122</td>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>1031570854573</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>6544.0</td>\n",
       "      <td>-7.280540e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>13355750</td>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>1072281226367</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>6372.0</td>\n",
       "      <td>-5.715962e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>13515242</td>\n",
       "      <td>2021-10-30</td>\n",
       "      <td>1117086238770</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>6370.0</td>\n",
       "      <td>-1.219012e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>13591634</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>1138287080480</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>6379.0</td>\n",
       "      <td>-1.299758e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>13673956</td>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>1161546692977</td>\n",
       "      <td>Geth</td>\n",
       "      <td>Default</td>\n",
       "      <td>6344.0</td>\n",
       "      <td>-4.929058e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      block_number chain_time_stamp     chain_size client_type sync_mode  \\\n",
       "20         7208771       2019-02-12   189825138765        Geth   Default   \n",
       "23         7221377       2019-02-15   191029043090        Geth   Default   \n",
       "26         7233897       2019-02-18   193137877427        Geth   Default   \n",
       "33         7263727       2019-02-25   196296727498        Geth   Default   \n",
       "43         7318905       2019-03-07   201604491690        Geth   Default   \n",
       "...            ...              ...            ...         ...       ...   \n",
       "965       13214122       2021-09-13  1031570854573        Geth   Default   \n",
       "987       13355750       2021-10-05  1072281226367        Geth   Default   \n",
       "1012      13515242       2021-10-30  1117086238770        Geth   Default   \n",
       "1024      13591634       2021-11-11  1138287080480        Geth   Default   \n",
       "1037      13673956       2021-11-24  1161546692977        Geth   Default   \n",
       "\n",
       "      block_diff    chain_diff  \n",
       "20        4189.0 -7.701860e+05  \n",
       "23        4174.0 -1.598000e+03  \n",
       "26        4147.0 -2.737614e+07  \n",
       "33        4063.0 -2.890617e+07  \n",
       "43        6414.0 -2.674129e+08  \n",
       "...          ...           ...  \n",
       "965       6544.0 -7.280540e+08  \n",
       "987       6372.0 -5.715962e+08  \n",
       "1012      6370.0 -1.219012e+09  \n",
       "1024      6379.0 -1.299758e+09  \n",
       "1037      6344.0 -4.929058e+08  \n",
       "\n",
       "[79 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etherscan_data[etherscan_data['chain_diff']<0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be no evident pattern for this behavior. For the seka of this project, we'll leavet the way it is, but in a real-life scenario, this should be taken care of. Let's persist the data, then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data persistance\n",
    "\n",
    "Let's persist these data in the same DB as with the trading data (an ```id``` surrogate key will be added):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data schema and etherscan table\n",
    "engine = create_engine(\n",
    "          'postgresql+psycopg2://postgres:postgres@localhost:5432/postgres'\n",
    "          )\n",
    "etherscan_tbl_creation = \"\"\"\n",
    "                         DROP TABLE IF EXISTS crypto.staging_etherscan;\n",
    "                         CREATE TABLE IF NOT EXISTS crypto.staging_etherscan(\n",
    "                                id SERIAL,\n",
    "                                block_number INT,\n",
    "                                date_time TIMESTAMP,\n",
    "                                chain_size BIGINT,\n",
    "                                client_type VARCHAR(50),\n",
    "                                sync_mode VARCHAR(50)\n",
    "                                );\n",
    "                         \"\"\"\n",
    "with engine.connect() as con:\n",
    "    con.execute(etherscan_tbl_creation)\n",
    "    etherscan_data = etherscan_data[['block_number', \n",
    "                                    'chain_time_stamp', \n",
    "                                    'chain_size', \n",
    "                                    'client_type', \n",
    "                                    'sync_mode']]\n",
    "    etherscan_data = etherscan_data.rename(columns={'chain_time_stamp':\n",
    "                                                    'date_time'})\n",
    "    etherscan_data.to_sql('staging_etherscan',                   \n",
    "                            con, \n",
    "                            schema = 'crypto',\n",
    "                            if_exists = 'append',\n",
    "                            index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new view will be created for the main fact table, which will be the table to go whenever analytical needs must be addressed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data schema and fact table\n",
    "engine = create_engine(\n",
    "          'postgresql+psycopg2://postgres:postgres@localhost:5432/postgres'\n",
    "          )\n",
    "fact_tbl_creation = \"\"\"\n",
    "                        DROP VIEW IF EXISTS crypto.fact_analytical;\n",
    "                        CREATE VIEW crypto.fact_analytical AS(\n",
    "\n",
    "                            WITH etherscan AS (\n",
    "                                SELECT \n",
    "                                    e.block_number\t\t\t\n",
    "                                    , DATE_TRUNC('day', e.date_time) date_truncated\t\t\t\n",
    "                                    , e.chain_size\n",
    "                                FROM \n",
    "                                    crypto.staging_etherscan e\n",
    "                            ),\n",
    "                            \n",
    "                            trading AS (\n",
    "                                SELECT \n",
    "                                    t.date_time\n",
    "                                    , DATE_TRUNC('day', t.date_time) date_truncated\n",
    "                                    , t.open_price\n",
    "                                    , t.high_price\n",
    "                                    , t.low_price\n",
    "                                    , t.close_price\t\t\t\n",
    "                                    \n",
    "                                FROM \n",
    "                                    crypto.staging_trading t\n",
    "                            )\n",
    "                            \n",
    "                            SELECT \n",
    "                                *\n",
    "                            FROM \n",
    "                                trading t \n",
    "                            \n",
    "                            LEFT JOIN \n",
    "                                etherscan e\t \n",
    "                            \n",
    "                            USING \n",
    "                                (date_truncated)\n",
    "                        );\n",
    "                         \"\"\"\n",
    "with engine.connect() as con:\n",
    "    con.execute(etherscan_tbl_creation)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f16c7b7322ff3df82f92772e50ca1d1e34210baf43ea94d77c7ecb6d3cb4546e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
